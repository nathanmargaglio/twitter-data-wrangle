{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we were tasked with wrangling and analyzing data related to the WeRateDogs Twitter account.  This process invloved gathering data from multiple sources, assessing the quality and tidiness of the data, cleaning the data, then performing analysis on the newly created masterset of data.\n",
    "\n",
    "#### Gathering Data\n",
    "\n",
    "In this project, we need to use data from three different sources:\n",
    "\n",
    "- A file, titled `twitter_archive_enhanced.csv`, which is given to us\n",
    "- A file, titled `image_predictions.tsv`, which we needed to download programmatically from an online resource\n",
    "- The Twitter API, which we required us to interact with Twitter's REST API to programmatically download tweet data\n",
    "\n",
    "The first file, `twitter_archive_enhanced.csv`, was downloaded and then uploaded to the Jupyter notebook server.  The second file, `image_predictions.tsv`, was downloaded in the `wrangle_act.ipynb` notebook using Python's request library.  The Twitter API was accessed in the `twitter_data_fetch.ipynb` notebook using the `tweepy` library.\n",
    "\n",
    "In order to access the Twitter API, I had to create an 'application' on Twitter and use the keys they provide to authenticate.  Then, I used the tweet IDs in the `twitter_archive_enhanced.csv` to query the API for relevant information (specifically, retweet and favorite counts).  I compiled the data in a pandas DataFrame, then saved it as a txt file, 'tweet_json.txt', in JSON format.\n",
    "\n",
    "After collecting all the data, I imported each file into it's own pandas DataFrame.\n",
    "\n",
    "#### Assessing Data\n",
    "\n",
    "After importing the data, I printed each DataFrame to visually inspect them.  I noted each column and described what I inferred the column to represent.  Right away, I noticed issues where some columns that should have had data that was just a string of digits (such as `retweeted_status_id`) was being represented as a float in scientific notation.\n",
    "\n",
    "I then used each DataFrame's `info()` method and noted the column types.  I saw that there were some columns that were being represented as integers where they should have been objects, such as `tweet_id`.\n",
    "\n",
    "Next, I examined the \"dog types\" (e.g., \"pupper\", \"doggo\", etc.) that were present in each observation.  I realized that the data was untidy in that one variable was being represented in four columns.  I also noticed that 14 observations had mutliple dog types (which can't happen).\n",
    "\n",
    "I also noticed that there were some observations in which the name of the dog was entered as \"quite\".  This was a mistake made during parsing of the tweet body.  There were a number of similar naming mistakes through the set.\n",
    "\n",
    "I used the DataFrame's `value_counts()` method to display the counts for each value in the `rating_numerator` column and saw that a majority of the values were between 4 and 14.  I examined a tweet with a `rating_numerator` of 1 to find that the tweet body mentions a '3 1/2 legged' dog, indicating another parsing error.\n",
    "\n",
    "Similar to analyzing the `rating_numerator`, I examined the `rating_denominator` to find a vast majority of denominators entered were 10.\n",
    "\n",
    "Many more observations were made during this process, some of which had direct impact on how cleaned the data while others were used to gain context in the set.\n",
    "\n",
    "#### Cleaning Data\n",
    "\n",
    "In this section, I noted multiple quality and tidiness issues to be cleaned.  First, I made copies of each of the DataFrames using their `copy()` method.  Next, I went through each issue I noted and defined the problem, coded a solution, and tested it.\n",
    "\n",
    "Some of the issues were as straight forward as replacing values (such as replacing 'doggo' in the `doggo` column of tweet `855851453814013952` with `None`) while others required converting column data types (such as from object to datetime).\n",
    "\n",
    "For the issue where values were interpreted as floats instead of objects, I had to convert the value to be represented as a string of digits instead of in scientifc notation, then cast the column as an object type.\n",
    "\n",
    "In the case where we had to convert the doggo, floofer, pupper, and puppo columns to one column, I had to iterate through each observation and place the result of which column had text in it into a new `dog_type` column.  I also had to handle the case where multiple dog types were present.\n",
    "\n",
    "#### Storing Data\n",
    "\n",
    "After cleaning the data, I merged each DataFrame based on their `twitter_id` columns (or in the case of the Twitter API data, `id`) using an inner join.  The result was one DataFrame with all the data present and cleaned.  I then saved the DataFrame as a csv file, `twitter_archive_master.csv`, using the DataFrame's `to_csv()` method."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
